1:"$Sreact.fragment"
2:I[97367,["/quantibench/_next/static/chunks/ff1a16fafef87110.js","/quantibench/_next/static/chunks/d2be314c3ece3fbe.js"],"ViewportBoundary"]
3:I[97367,["/quantibench/_next/static/chunks/ff1a16fafef87110.js","/quantibench/_next/static/chunks/d2be314c3ece3fbe.js"],"MetadataBoundary"]
4:"$Sreact.suspense"
5:I[27201,["/quantibench/_next/static/chunks/ff1a16fafef87110.js","/quantibench/_next/static/chunks/d2be314c3ece3fbe.js"],"IconMark"]
0:{"buildId":"JMB6p3sw99J81YInPv3ZR","rsc":["$","$1","h",{"children":[null,["$","$L2",null,{"children":[["$","meta","0",{"charSet":"utf-8"}],["$","meta","1",{"name":"viewport","content":"width=device-width, initial-scale=1"}]]}],["$","div",null,{"hidden":true,"children":["$","$L3",null,{"children":["$","$4",null,{"name":"Next.Metadata","children":[["$","title","0",{"children":"QuantiBench — LLM Quantization Benchmarks"}],["$","meta","1",{"name":"description","content":"We benchmarked 5 popular open-source LLMs at 8 quantization levels across 5 rigorous evaluation suites, measuring exactly how much quality you keep — and what you trade for speed and size."}],["$","meta","2",{"property":"og:title","content":"QuantiBench — LLM Quantization Benchmarks"}],["$","meta","3",{"property":"og:description","content":"Does quantization harm LLM performance? We measured it."}],["$","meta","4",{"property":"og:url","content":"https://quantibench.ai"}],["$","meta","5",{"property":"og:site_name","content":"QuantiBench"}],["$","meta","6",{"property":"og:type","content":"website"}],["$","meta","7",{"name":"twitter:card","content":"summary"}],["$","meta","8",{"name":"twitter:title","content":"QuantiBench — LLM Quantization Benchmarks"}],["$","meta","9",{"name":"twitter:description","content":"Does quantization harm LLM performance? We measured it."}],["$","link","10",{"rel":"icon","href":"/favicon.svg"}],["$","$L5","11",{}]]}]}]}],["$","meta",null,{"name":"next-size-adjust","content":""}]]}],"loading":null,"isPartial":false}
